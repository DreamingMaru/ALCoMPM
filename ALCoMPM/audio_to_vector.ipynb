{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":18104,"status":"ok","timestamp":1682758827927,"user":{"displayName":"김하림","userId":"07896888156034124009"},"user_tz":-540},"id":"KRwEldkSvNuO","outputId":"d77f90e0-1918-41da-9736-fa5dad26ef2f"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":741,"status":"ok","timestamp":1682758847290,"user":{"displayName":"김하림","userId":"07896888156034124009"},"user_tz":-540},"id":"04IkmQUfvUgU","outputId":"bca1e851-3d89-4068-801e-d144fed62d86"},"outputs":[{"name":"stdout","output_type":"stream","text":["/content/drive/MyDrive/Colab Notebooks\n"]}],"source":["cd /content/drive/MyDrive/Colab Notebooks/"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KVh12k7kvb0u"},"outputs":[],"source":["import pandas as pd\n","import os, librosa"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":54},"executionInfo":{"elapsed":2,"status":"ok","timestamp":1682758851892,"user":{"displayName":"김하림","userId":"07896888156034124009"},"user_tz":-540},"id":"9n3hcoK9vgtJ","outputId":"7d5398ad-4d69-4c3a-bf4d-a964cf7dd1f4"},"outputs":[{"data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["\"\\n#스크립트별로 얻을 때\\nscript_set, speaker_dict, audio_dict, emotion_dict, sentiment_dict = process_by_script('Sess01_eval.csv')\\n\\nprint(script_set)\\nprint(speaker_dict)\\nprint(audio_dict)\\nprint(emotion_dict)\\nprint(sentiment_dict)\\n\""]},"execution_count":5,"metadata":{},"output_type":"execute_result"}],"source":["import pandas as pd\n","import librosa\n","import numpy as np\n","from tqdm import tqdm\n","\n","# 음성정보 배열로 처리\n","def load_wav(wav_path):\n","  wav, _ = librosa.load(wav_path, sr=8000)\n","  return wav\n","\n","# 스크립트별로 전처리\n","def preprocess_audio(csv):\n","  \n","  df = pd.read_csv(csv)\n","  seg_id = list(df['Segment ID'][1:])\n","  \n","  # 모아야 할 정보!\n","  speaker = []\n","  audio = []\n","  '''\n","  emotion = df['Total Evaluation'][1:]\n","  sentiment = []\n","  \n","  sentidict = {'positive': [\"joy\"], 'negative': [\"anger\", \"disgust\", \"fear\", \"sadness\"], 'neutral': [\"neutral\", \"surprise\"]}\n","  \n","  #센티먼트 담기\n","  for emo in emotion:\n","    for sent, emo_list in sentidict.items():\n","       if emo in emo_list:\n","          sentiment.append(sent)\n","  '''\n","\n","  # 오디오 담기(csv 파일에 있는 seg id 순서대로)\n","  for segment in tqdm(seg_id):\n","    wav = load_wav('audio/'+segment+'.wav')  \n","    audio.append(wav)\n","  \n","  \n","  # 스크립트 구분(세션번호 + 스크립트번호), 화자 이름 담기\n","  script_id = []\n","\n","  for id in seg_id:\n","    id = id.split('_')\n","    script_id.append(id[0] + '_' + id[1])\n","    speaker.append(id[2])\n","  \n","  '''\n","  # 스크립트별로 담을 때!\n","  script_set = sorted(list(set(script_id)))\n","\n","  speaker_dict = {id:[] for id in script_set}\n","  audio_dict = {id:np.array([]).astype(np.float32) for id in script_set}\n","  emotion_dict = {id:[] for id in script_set}\n","  sentiment_dict = {id:[] for id in script_set}\n","  \n"," \n","  for id, spk in zip(script_id, speaker):\n","    speaker_dict[id].append(spk)\n","    \n","  for id, wav in zip(script_id, audio):\n","    audio_dict[id] = np.concatenate((audio_dict[id], wav))\n","    \n","  for id, emo in zip(script_id, emotion):\n","    emotion_dict[id].append(emo)\n","\n","  for id, snt in zip(script_id, sentiment):\n","    sentiment_dict[id].append(snt)\n","    \n","  return script_set, speaker_dict, audio_dict, emotion_dict, sentiment_dict\n","  '''\n","  return seg_id, script_id, speaker, audio  # 리스트 출력, 정확히 담화 순서대로 담겨있음\n","'''\n","#스크립트별로 얻을 때\n","script_set, speaker_dict, audio_dict, emotion_dict, sentiment_dict = process_by_script('Sess01_eval.csv')\n","\n","print(script_set)\n","print(speaker_dict)\n","print(audio_dict)\n","print(emotion_dict)\n","print(sentiment_dict)\n","'''"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qm0zBZvqKrAk"},"outputs":[],"source":["total_seg_id = []\n","total_script_id = []\n","total_speaker = []\n","total_audio = []"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"UVejWtd6POvn","outputId":"5a8a846b-0437-49c2-e1a4-e98416833dc2"},"outputs":[{"name":"stderr","output_type":"stream","text":["100%|██████████| 311/311 [04:30<00:00,  1.15it/s]\n","100%|██████████| 265/265 [02:53<00:00,  1.52it/s]\n","100%|██████████| 341/341 [03:42<00:00,  1.53it/s]\n","100%|██████████| 362/362 [04:00<00:00,  1.50it/s]\n","100%|██████████| 270/270 [02:58<00:00,  1.51it/s]\n","100%|██████████| 322/322 [03:30<00:00,  1.53it/s]\n","100%|██████████| 365/365 [04:05<00:00,  1.48it/s]\n","100%|██████████| 383/383 [04:13<00:00,  1.51it/s]\n","100%|██████████| 428/428 [04:51<00:00,  1.47it/s]\n","100%|██████████| 320/320 [03:35<00:00,  1.49it/s]\n","100%|██████████| 316/316 [03:30<00:00,  1.50it/s]\n","100%|██████████| 326/326 [03:33<00:00,  1.53it/s]\n","100%|██████████| 407/407 [04:27<00:00,  1.52it/s]\n"," 25%|██▌       | 83/329 [00:52<02:34,  1.59it/s]"]}],"source":["csv_list = sorted(os.listdir('annotation'))\n","\n","for csv_path in csv_list:\n","  seg_id, script_id, speaker, audio = preprocess_audio('annotation/'+csv_path)\n","  total_seg_id += seg_id \n","  total_script_id += script_id\n","  total_speaker += speaker \n","  total_audio += audio\n","\n","print(len(total_seg_id), len(total_script_id), len(total_speaker), len(total_audio))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1oBe6eQONthO"},"outputs":[],"source":["!pip install transformers"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8JGUL71bWHCr"},"outputs":[],"source":["from transformers import Wav2Vec2Model, Wav2Vec2Processor\n","import torch"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"aU5YXSbwhgWg"},"outputs":[],"source":["# 오디오 데이터를 텐서로 변환\n","audio_ds = []\n","for wav in tqdm(total_audio):\n","  w = torch.FloatTensor(wav)\n","  audio_ds.append(w)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"caAicYsLcJf8"},"outputs":[],"source":["# pretrained Wav2Vec2 불러오기\n","processor = Wav2Vec2Processor.from_pretrained(\"kresnik/wav2vec2-large-xlsr-korean\")\n","encoder = Wav2Vec2Model.from_pretrained(\"kresnik/wav2vec2-large-xlsr-korean\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"FSgbVV5GYOW3"},"outputs":[],"source":["# wav data 배열 모델에 넣어서 인코딩\n","def encoding(wav_arr, processor = None, encoder = None, return_hidden_state=False):\n","    \n","    assert bool(processor) == bool(encoder)\n","    \n","    inputs = processor(wav_arr,\n","                       sampling_rate=16000,\n","                       return_attention_mask=True,\n","                       return_tensors=\"pt\")\n","    \n","    Inputs = inputs.to('cuda')\n","    Encoder = encoder.to('cuda')\n","    outputs = encoder(output_hidden_states=return_hidden_state, **inputs)\n","\n","    return outputs"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nYnp0RYSY9lV"},"outputs":[],"source":["# hidden, feature vector 추출\n","\n","def extract_vector(data):\n","  with torch.no_grad():\n","    encoded = encoding(data, processor = processor, encoder = encoder, return_hidden_state=True)  # encoding 함수 사용\n","\n","    hidden_vec = encoded.last_hidden_state.mean(dim=1).tolist()                                                         \n","    feature_vec = encoded.extract_features.mean(dim=1).tolist()\n","\n","    return hidden_vec, feature_vec"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9zwM-vkctMiI"},"outputs":[],"source":["# hidden, feature vector 뽑기\n","total_hidden_vector = []\n","total_feature_vector = []\n","\n","for wav in tqdm(audio_ds):\n","  hidden, feature = extract_vector(wav)\n","  total_hidden_vector.append(hidden)\n","  total_feature_vector.append(feature)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7i0E_wP_T4Lx"},"outputs":[],"source":["print(len(total_hidden_vector), len(total_feature_vector))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mo66OPOss_jw"},"outputs":[],"source":["# 항목: seg_id, script_id, speaker, hidden_vector, feature_vector \n","# 같은 인덱스 = 같은 발화 정보\n","\n","total_dataset = {'seg_ID': total_seg_id,\n","                 'script_id': total_script_id,\n","                 'speaker': total_speaker,\n","                 'hidden_vector': total_hidden_vector,\n","                 'feature_vector': total_feature_vector}      "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"X6_DDq5R61gl"},"outputs":[],"source":["total_dataset = []\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"FdJVlS08K3p8"},"outputs":[],"source":["#json 파일로 내보내기\n","import json\n","with open('total_dataset.json', 'w') as f : \n","\tjson.dump(total_dataset, f)"]}],"metadata":{"colab":{"provenance":[]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}